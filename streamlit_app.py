from operator import truediv
import streamlit as st
import cv2
import numpy as np
from pyzbar.pyzbar import decode
import pandas as pd
from datetime import datetime
import os
import tempfile
from PIL import Image,ImageDraw
import av
from contextlib import contextmanager
import tempfile
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
from facenet_pytorch import MTCNN, InceptionResnetV1
import torch
import torch.nn.functional as F
import time
import matplotlib.pyplot as plt

# Th√™m try-except cho import asyncio ƒë·ªÉ x·ª≠ l√Ω l·ªói li√™n quan ƒë·∫øn asyncio
try:
    import asyncio
    import threading
    import uuid
    import json
    from typing import List, Dict, Any, Optional
    from aiortc import RTCPeerConnection, RTCSessionDescription, VideoStreamTrack
    from aiortc.contrib.media import MediaPlayer, MediaRecorder, MediaRelay
    import logging
    AIORTC_AVAILABLE = True
except ImportError as e:
    AIORTC_AVAILABLE = False
    st.warning(f"aiortc kh√¥ng kh·∫£ d·ª•ng: {str(e)}. Ch·ªâ s·ª≠ d·ª•ng ch·ª©c nƒÉng upload ·∫£nh.")

# Thi·∫øt l·∫≠p giao di·ªán trang
st.set_page_config(
    page_title="H·ªÜ TH·ªêNG QU·∫¢N L√ù C√îNG D√ÇN",
    page_icon="üìã",
    layout="wide",
    initial_sidebar_state="expanded"
)

# C·∫•u h√¨nh logging cho aiortc
if AIORTC_AVAILABLE:
    logging.basicConfig(level=logging.INFO)

# L∆∞u tr·ªØ c√°c k·∫øt n·ªëi peer
peer_connections = {}
videoframes = {}
class ObjectDetectionTransformer(VideoProcessorBase):
    def __init__(self):
        # Kh·ªüi t·∫°o MTCNN cho Detect khu√¥n m·∫∑t
        self.mtcnn = MTCNN(
            image_size=160, 
            margin=20, 
            min_face_size=20,
            thresholds=[0.6, 0.7, 0.7],  # Ng∆∞·ª°ng Detect ba b∆∞·ªõc
            factor=0.709, 
            post_process=True,
            device='cuda' if torch.cuda.is_available() else 'cpu'
        )
        
        # Kh·ªüi t·∫°o FaceNet model
        self.facenet = InceptionResnetV1(pretrained='vggface2').eval()
        if torch.cuda.is_available():
            self.facenet = self.facenet.cuda()
            
        # Bi·∫øn ƒë·ªÉ l∆∞u tr·ªØ embedding khu√¥n m·∫∑t
        self.known_face_embeddings = []
        self.known_face_names = []
        
        # Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh khu√¥n m·∫∑t gi·ªëng nhau
        self.similarity_threshold = 0.6
        
        # B·ªô ƒë·∫øm ƒë·ªÉ t·ª± ƒë·ªông ƒë·∫∑t t√™n cho khu√¥n m·∫∑t m·ªõi
        self.face_counter = 1

    def get_face_embedding(self, face_tensor):
        """Tr√≠ch xu·∫•t embedding t·ª´ tensor khu√¥n m·∫∑t"""
        try:
            with torch.no_grad():
                if torch.cuda.is_available():
                    face_tensor = face_tensor.cuda()
                embedding = self.facenet(face_tensor.unsqueeze(0))
                return F.normalize(embedding, p=2, dim=1)
        except:
            return None

    def find_matching_face(self, new_embedding):
        """T√¨m khu√¥n m·∫∑t kh·ªõp trong danh s√°ch Knowed"""
        if len(self.known_face_embeddings) == 0:
            return None, -1
        
        # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng v·ªõi t·∫•t c·∫£ khu√¥n m·∫∑t Knowed
        similarities = []
        for known_embedding in self.known_face_embeddings:
            similarity = F.cosine_similarity(new_embedding, known_embedding).item()
            similarities.append(similarity)
        
        # T√¨m ƒë·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t
        max_similarity = max(similarities)
        max_index = similarities.index(max_similarity)
        
        # Ki·ªÉm tra xem c√≥ v∆∞·ª£t ng∆∞·ª°ng kh√¥ng
        if max_similarity > self.similarity_threshold:
            return self.known_face_names[max_index], max_similarity
        else:
            return None, max_similarity

    def add_new_face(self, embedding, name=None):
        """Th√™m khu√¥n m·∫∑t m·ªõi v√†o danh s√°ch"""
        if name is None:
            name = f"suspect {self.face_counter}"
            self.face_counter += 1
        
        self.known_face_embeddings.append(embedding)
        self.known_face_names.append(name)
        print(f"ƒê√£ th√™m khu√¥n m·∫∑t m·ªõi: {name}")

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        
        # Chuy·ªÉn ƒë·ªïi t·ª´ BGR sang RGB (MTCNN s·ª≠ d·ª•ng RGB)
        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # Detect khu√¥n m·∫∑t b·∫±ng MTCNN
        boxes, probs, landmarks = self.mtcnn.detect(rgb_img, landmarks=True)
        
        # V·∫Ω c√°c khu√¥n m·∫∑t ƒë∆∞·ª£c Detect
        if boxes is not None:
            for i, (box, landmark) in enumerate(zip(boxes, landmarks)):
                # L·∫•y t·ªça ƒë·ªô khu√¥n m·∫∑t
                x1, y1, x2, y2 = [int(p) for p in box]
                
                # V·∫Ω h√¨nh ch·ªØ nh·∫≠t xung quanh khu√¥n m·∫∑t
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # V·∫Ω c√°c ƒëi·ªÉm landmark (m·∫Øt, m≈©i, mi·ªáng)
                for p in landmark:
                    cv2.circle(img, (int(p[0]), int(p[1])), 2, (0, 0, 255), -1)
                
                # Tr√≠ch xu·∫•t v√† x·ª≠ l√Ω khu√¥n m·∫∑t
                try:
                    # C·∫Øt v√πng khu√¥n m·∫∑t t·ª´ ·∫£nh RGB
                    face_img = rgb_img[max(0, y1):min(rgb_img.shape[0], y2), 
                                     max(0, x1):min(rgb_img.shape[1], x2)]
                    
                    # S·ª≠ d·ª•ng MTCNN ƒë·ªÉ chu·∫©n h√≥a khu√¥n m·∫∑t
                    face_tensor = self.mtcnn(face_img)
                    
                    if face_tensor is not None:
                        # Tr√≠ch xu·∫•t embedding
                        embedding = self.get_face_embedding(face_tensor)
                        
                        if embedding is not None:
                            # T√¨m khu√¥n m·∫∑t kh·ªõp
                            matched_name, similarity = self.find_matching_face(embedding)
                            
                            if matched_name:
                                # Khu√¥n m·∫∑t Knowed
                                label = f"{matched_name} ({similarity:.2f})"
                                color = (0, 255, 0)  # Xanh l√° cho khu√¥n m·∫∑t Knowed
                            else:
                                # Khu√¥n m·∫∑t m·ªõi - th√™m v√†o danh s√°ch
                                self.add_new_face(embedding)
                                label = f"suspect {self.face_counter - 1} (New)"
                                color = (0, 0, 255)  # ƒê·ªè cho khu√¥n m·∫∑t m·ªõi
                            
                            # Hi·ªÉn th·ªã t√™n/nh√£n
                            cv2.putText(img, label, (x1, y1-30), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                
                except Exception as e:
                    print(f"L·ªói x·ª≠ l√Ω khu√¥n m·∫∑t: {e}")
                
                # Hi·ªÉn th·ªã x√°c su·∫•t Detect
                confidence = f"Reliability: {probs[i]:.2f}"
                cv2.putText(img, confidence, (x1, y1-10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
        
        # Hi·ªÉn th·ªã th·ªëng k√™
        if boxes is not None:
            face_count = len(boxes)
            cv2.putText(img, f"detected: {face_count} | Knowed: {len(self.known_face_embeddings)}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        else:
            cv2.putText(img, f"detect: 0 | Knowed: {len(self.known_face_embeddings)}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        return av.VideoFrame.from_ndarray(img, format="bgr24")

    def get_known_faces_info(self):
        """Tr·∫£ v·ªÅ th√¥ng tin c√°c khu√¥n m·∫∑t Knowed"""
        return {
            "total_faces": len(self.known_face_embeddings),
            "face_names": self.known_face_names.copy()
        }
    
    def clear_known_faces(self):
        """X√≥a t·∫•t c·∫£ khu√¥n m·∫∑t ƒë√£ l∆∞u"""
        self.known_face_embeddings.clear()
        self.known_face_names.clear()
        self.face_counter = 1
        print("ƒê√£ x√≥a t·∫•t c·∫£ khu√¥n m·∫∑t ƒë√£ l∆∞u")

# CSS t√πy ch·ªânh
st.markdown("""
    <style>
    .main {
        padding: 20px;
    }
    .stButton>button {
        width: 100%;
        margin-top: 10px;
        background-color: #0066cc;
        color: white;
        border-radius: 5px;
        padding: 10px 20px;
        transition: all 0.3s ease;
    }
    .stButton>button:hover {
        background-color: #004d99;
        transform: translateY(-2px);
        box-shadow: 0 2px 5px rgba(0,0,0,0.2);
    }
    .success-message {
        padding: 20px;
        background-color: #4CAF50;
        color: white;
        margin-bottom: 15px;
        border-radius: 5px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    .error-message {
        padding: 20px;
        background-color: #f44336;
        color: white;
        margin-bottom: 15px;
        border-radius: 5px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    .info-card {
        padding: 20px;
        background-color: #f8f9fa;
        border-radius: 10px;
        margin-bottom: 20px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    .info-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }
    .feature-button {
        background-color: #ffffff;
        border: 1px solid #ddd;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
        margin: 10px;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    .feature-button:hover {
        transform: translateY(-5px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
    }
    .camera-feed {
        border-radius: 10px;
        overflow: hidden;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    .sidebar .sidebar-content {
        background-color: #f8f9fa;
    }
    .login-form {
        max-width: 500px;
        margin: 0 auto;
        padding: 30px;
        background-color: #f8f9fa;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    .login-header {
        text-align: center;
        margin-bottom: 20px;
    }
    </style>
    """, unsafe_allow_html=True)


# Kh·ªüi t·∫°o session state
if 'citizens_data' not in st.session_state:
    st.session_state.citizens_data = pd.DataFrame(columns=[
        'id', 'cccd', 'name', 'dob', 'sex', 'address', 'expdate', 'scan_date', 'image_path'
    ])

# Th√™m session state cho ƒëƒÉng nh·∫≠p
if 'logged_in' not in st.session_state:
    st.session_state.logged_in = False

if 'username' not in st.session_state:
    st.session_state.username = ""

# Th√™m session state cho ƒëi·ªÅu h∆∞·ªõng trang
if 'page' not in st.session_state:
    st.session_state.page = None
    
# Th√™m session state cho menu choice
if 'menu_choice' not in st.session_state:
    st.session_state.menu_choice = "Trang ch·ªß"

# Th√™m session state cho aiortc
if 'peer_connection_id' not in st.session_state:
    st.session_state.peer_connection_id = None

if 'video_processor' not in st.session_state:
    st.session_state.video_processor = None

# Danh s√°ch t√†i kho·∫£n m·∫´u (trong th·ª±c t·∫ø n√™n l∆∞u trong c∆° s·ªü d·ªØ li·ªáu v√† m√£ h√≥a m·∫≠t kh·∫©u)
USERS = {
    "admin": "admin123",
    "user": "user123"
}

# ICE servers configuration for aiortc

@st.cache_resource
def load_face_models():
    # Kh·ªüi t·∫°o MTCNN cho Detect khu√¥n m·∫∑t
    mtcnn = MTCNN(
        image_size=160, 
        margin=20, 
        min_face_size=20,
        thresholds=[0.6, 0.7, 0.7],
        factor=0.709, 
        post_process=True,
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    
    # Kh·ªüi t·∫°o FaceNet model
    facenet = InceptionResnetV1(pretrained='vggface2').eval()
    if torch.cuda.is_available():
        facenet = facenet.cuda()
        
    return mtcnn, facenet

# H√†m Detect khu√¥n m·∫∑t trong ·∫£nh
def detect_faces_in_image(image, mtcnn):
    # Chuy·ªÉn ƒë·ªïi ·∫£nh PIL sang numpy array n·∫øu c·∫ßn
    if isinstance(image, Image.Image):
        img_array = np.array(image)
    else:
        img_array = image
    
    # Chuy·ªÉn ƒë·ªïi sang RGB n·∫øu l√† BGR (t·ª´ OpenCV)
    if img_array.shape[2] == 3 and not isinstance(image, Image.Image):
        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)
    
    # Detect khu√¥n m·∫∑t
    boxes, probs, landmarks = mtcnn.detect(img_array, landmarks=True)
    
    return boxes, probs, landmarks, img_array

# H√†m v·∫Ω k·∫øt qu·∫£ Detect l√™n ·∫£nh
def draw_faces_on_image(image, boxes, probs, landmarks):
    # T·∫°o b·∫£n sao ƒë·ªÉ v·∫Ω l√™n
    if isinstance(image, np.ndarray):
        # N·∫øu l√† numpy array, chuy·ªÉn th√†nh PIL Image
        result_image = Image.fromarray(image)
    else:
        # N·∫øu ƒë√£ l√† PIL Image, t·∫°o b·∫£n sao
        result_image = image.copy()
    
    draw = ImageDraw.Draw(result_image)
    
    # V·∫Ω c√°c khu√¥n m·∫∑t ƒë∆∞·ª£c Detect
    if boxes is not None:
        for i, (box, landmark) in enumerate(zip(boxes, landmarks)):
            # V·∫Ω h√¨nh ch·ªØ nh·∫≠t xung quanh khu√¥n m·∫∑t
            draw.rectangle([(box[0], box[1]), (box[2], box[3])], 
                           outline="green", width=3)
            
            # V·∫Ω c√°c ƒëi·ªÉm landmark
            for p in landmark:
                draw.ellipse((p[0]-2, p[1]-2, p[0]+2, p[1]+2), 
                             fill="red")
            
            # Hi·ªÉn th·ªã ƒë·ªô tin c·∫≠y
            text_position = (box[0], box[1] - 15)
            confidence = f"Conf: {probs[i]:.2f}"
            draw.text(text_position, confidence, fill="green")
    
    # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng khu√¥n m·∫∑t
    if boxes is not None:
        face_count = len(boxes)
        draw.text((10, 10), f"S·ªë khu√¥n m·∫∑t: {face_count}", fill="green")
    
    return result_image
ho_list = ["Nguy·ªÖn", "Tr·∫ßn", "L√™", "Ph·∫°m", "Ho√†ng", "V≈©", "ƒê·∫∑ng", "B√πi", "Ng√¥", "ƒêinh"]
ten_dem_list = ["VƒÉn", "Th·ªã", "Minh", "H·ªØu", "ƒê·ª©c", "Thanh", "Quang", "Anh"]
ten_list = ["An", "B√¨nh", "C∆∞·ªùng", "Dung", "Em", "Ph∆∞∆°ng", "Giang", "Hoa", "Inh", "Kim"]
import random
# H√†m x·ª≠ l√Ω video
def process_video(video_path, mtcnn, output_path=None):
    cap = cv2.VideoCapture(video_path)
    
    # L·∫•y th√¥ng tin video
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # Kh·ªüi t·∫°o FaceNet model ƒë·ªÉ tr√≠ch xu·∫•t embedding
    facenet = InceptionResnetV1(pretrained='vggface2').eval()
    if torch.cuda.is_available():
        facenet = facenet.cuda()
    
    # Bi·∫øn l∆∞u tr·ªØ khu√¥n m·∫∑t Knowed
    known_face_embeddings = []
    known_face_names = []
    known_face_images = []
    face_counter = 1
    similarity_threshold = 0.6
    
    # T·∫°o video output n·∫øu c·∫ßn
    if output_path:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))
    
    # T·∫°o thanh ti·∫øn tr√¨nh
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    frame_count = 0
    face_count_per_frame = []
    
    def get_face_embedding(face_tensor):
        """Tr√≠ch xu·∫•t embedding t·ª´ tensor khu√¥n m·∫∑t"""
        try:
            with torch.no_grad():
                if torch.cuda.is_available():
                    face_tensor = face_tensor.cuda()
                embedding = facenet(face_tensor.unsqueeze(0))
                return F.normalize(embedding, p=2, dim=1)
        except:
            return None
    
    def find_matching_face(new_embedding):
        """T√¨m khu√¥n m·∫∑t kh·ªõp trong danh s√°ch Knowed"""
        if len(known_face_embeddings) == 0:
            return None, -1
        
        # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng v·ªõi t·∫•t c·∫£ khu√¥n m·∫∑t Knowed
        similarities = []
        for known_embedding in known_face_embeddings:
            similarity = F.cosine_similarity(new_embedding, known_embedding).item()
            similarities.append(similarity)
        
        # T√¨m ƒë·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t
        max_similarity = max(similarities)
        max_index = similarities.index(max_similarity)
        
        # Ki·ªÉm tra xem c√≥ v∆∞·ª£t ng∆∞·ª°ng kh√¥ng
        if max_similarity > similarity_threshold:
            return known_face_names[max_index], max_similarity
        else:
            return None, max_similarity
   

    
    face_counter += 1
    def add_new_face(embedding,face_img, name=None):
        """Th√™m khu√¥n m·∫∑t m·ªõi v√†o danh s√°ch"""
        nonlocal face_counter
        if name is None:
            _random_citizen= get_random_citizen_info()
            if(_random_citizen==None):
                ho = random.choice(ho_list)
                ten_dem = random.choice(ten_dem_list)
                ten = random.choice(ten_list)
                name = f"{ho} {ten_dem} {ten}"
            else:
                
                name = _random_citizen['name']
    
    # ƒê·∫£m b·∫£o kh√¥ng tr√πng t√™n
            # while name in known_face_names:
            #     ho = random.choice(ho_list)
            #     ten_dem = random.choice(ten_dem_list)
            #     ten = random.choice(ten_list)
            #     name = f"{ho} {ten_dem} {ten}"
        if(name not in known_face_names):
            known_face_embeddings.append(embedding)
            known_face_names.append(name)
            known_face_images.append(face_img)
            print(f"ƒê√£ th√™m khu√¥n m·∫∑t m·ªõi: {name}")
        return name
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # Chuy·ªÉn ƒë·ªïi t·ª´ BGR sang RGB cho MTCNN
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # Detect khu√¥n m·∫∑t
        boxes, probs, landmarks, _ = detect_faces_in_image(frame, mtcnn)
        
        # L∆∞u s·ªë l∆∞·ª£ng khu√¥n m·∫∑t
        if boxes is not None:
            face_count_per_frame.append(len(boxes))
        else:
            face_count_per_frame.append(0)
        
        # V·∫Ω k·∫øt qu·∫£ l√™n frame
        if boxes is not None:
            for i, (box, landmark) in enumerate(zip(boxes, landmarks)):
                # V·∫Ω h√¨nh ch·ªØ nh·∫≠t xung quanh khu√¥n m·∫∑t
                x1, y1, x2, y2 = [int(p) for p in box]
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # V·∫Ω c√°c ƒëi·ªÉm landmark
                for p in landmark:
                    cv2.circle(frame, (int(p[0]), int(p[1])), 2, (0, 0, 255), -1)
                
                # X·ª≠ l√Ω nh·∫≠n di·ªán khu√¥n m·∫∑t
                try:
                    # C·∫Øt v√πng khu√¥n m·∫∑t t·ª´ ·∫£nh RGB
                    face_img = rgb_frame[max(0, y1):min(rgb_frame.shape[0], y2), 
                                       max(0, x1):min(rgb_frame.shape[1], x2)]
                    
                    # S·ª≠ d·ª•ng MTCNN ƒë·ªÉ chu·∫©n h√≥a khu√¥n m·∫∑t
                    face_tensor = mtcnn(face_img)
                    
                    if face_tensor is not None:
                        # Tr√≠ch xu·∫•t embedding
                        embedding = get_face_embedding(face_tensor)
                        
                        if embedding is not None:
                            # T√¨m khu√¥n m·∫∑t kh·ªõp
                            matched_name, similarity = find_matching_face(embedding)
                            
                            if matched_name:
                                # Khu√¥n m·∫∑t Knowed
                                label = f"{matched_name} ({similarity:.2f})"
                                name_color = (0, 255, 0)  # Xanh l√° cho khu√¥n m·∫∑t Knowed
                            else:
                                # Khu√¥n m·∫∑t m·ªõi - th√™m v√†o danh s√°ch
                                new_name = add_new_face(embedding,face_img=face_img)
                                label = f"{new_name} (New)"
                                name_color = (0, 0, 255)  # ƒê·ªè cho khu√¥n m·∫∑t m·ªõi
                            
                            # Hi·ªÉn th·ªã t√™n/nh√£n
                            cv2.putText(frame, label, (x1, y1-30), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, name_color, 2)
                
                except Exception as e:
                    print(f"L·ªói x·ª≠ l√Ω khu√¥n m·∫∑t: {e}")
                    # Hi·ªÉn th·ªã nh√£n m·∫∑c ƒë·ªãnh n·∫øu c√≥ l·ªói
                    cv2.putText(frame, "Unknown", (x1, y1-30), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 2)
                
                # Hi·ªÉn th·ªã ƒë·ªô tin c·∫≠y
                confidence = f"Conf: {probs[i]:.2f}"
                cv2.putText(frame, confidence, (x1, y1-10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        # Hi·ªÉn th·ªã th·ªëng k√™
        if boxes is not None:
            face_count = len(boxes)
            stats_text = f"Detect: {face_count} | Knowed: {len(known_face_embeddings)}"
            cv2.putText(frame, stats_text, (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        else:
            stats_text = f"Detect: 0 | Knowed: {len(known_face_embeddings)}"
            cv2.putText(frame, stats_text, (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # Ghi frame v√†o video output n·∫øu c·∫ßn
        if output_path:
            out.write(frame)
        
        # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh
        frame_count += 1
        progress = int(frame_count / total_frames * 100)
        progress_bar.progress(progress / 100)
        status_text.text(f"ƒêang x·ª≠ l√Ω: {progress}% ({frame_count}/{total_frames}) - ƒê√£ nh·∫≠n di·ªán: {len(known_face_embeddings)} ng∆∞·ªùi")
    
    # Gi·∫£i ph√≥ng t√†i nguy√™n
    cap.release()
    if output_path:
        out.release()
    
    # T√≠nh to√°n th·ªëng k√™
    max_faces = max(face_count_per_frame) if face_count_per_frame else 0
    avg_faces = sum(face_count_per_frame) / len(face_count_per_frame) if face_count_per_frame else 0
    
    # Hi·ªÉn th·ªã danh s√°ch ng∆∞·ªùi ƒë√£ nh·∫≠n di·ªán
    st.success(f"Ho√†n th√†nh x·ª≠ l√Ω video!")
    st.info(f"ƒê√£ nh·∫≠n di·ªán {len(known_face_embeddings)} ng∆∞·ªùi kh√°c nhau:")
    for i, name in enumerate(known_face_names, 1):
        st.write(f"{i}. {name}")
    
    return {
        "total_frames": frame_count,
        "max_faces": max_faces,
        "avg_faces": avg_faces,
        "face_count_per_frame": face_count_per_frame,
        "known_faces": len(known_face_embeddings),
        "known_face_names": known_face_names.copy(),
        "known_face_embeddings": known_face_embeddings.copy(),
        "known_face_images":known_face_images.copy()
    }
def login_page():
    st.markdown("<h1 style='text-align: center;'>ƒêƒÉng nh·∫≠p H·ªá th·ªëng</h1>", unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("""
        <div class="info-card" style="padding: 30px;">
            <h3 style="text-align: center;">ƒêƒÉng nh·∫≠p</h3>
            <p style="text-align: center;">Vui l√≤ng nh·∫≠p th√¥ng tin ƒëƒÉng nh·∫≠p c·ªßa b·∫°n.</p>
        </div>
        """, unsafe_allow_html=True)
        
        username = st.text_input("T√™n ƒëƒÉng nh·∫≠p")
        password = st.text_input("M·∫≠t kh·∫©u", type="password")
        
        if st.button("ƒêƒÉng nh·∫≠p"):
            if username in USERS and USERS[username] == password:
                st.session_state.logged_in = True
                st.session_state.username = username
                st.success(f"ƒêƒÉng nh·∫≠p th√†nh c√¥ng! Ch√†o m·ª´ng, {username}")
                st.rerun()
            else:
                st.error("T√™n ƒëƒÉng nh·∫≠p ho·∫∑c m·∫≠t kh·∫©u kh√¥ng ƒë√∫ng!")



 
import requests
def surveillance_camera():
    st.markdown("<h2 style='text-align: center;'>Gi√°m s√°t Camera</h2>", unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        <div class="info-card">
        <h3>Gi√°m s√°t an ninh</h3>
        <p>Theo d√µi v√† Detect ƒë·ªëi t∆∞·ª£ng qua camera</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Add option to choose between aiortc and file upload
        camera_option = st.radio(
            "Ch·ªçn ph∆∞∆°ng th·ª©c:",
            ["Camera tr·ª±c ti·∫øp", "Upload video/·∫£nh"],
            key="camera_option"
        )
        
        if camera_option == "Camera tr·ª±c ti·∫øp":
            try:
                if AIORTC_AVAILABLE:
                    response = requests.get(
                        "https://iewcom1.metered.live/api/v1/turn/credentials",
                        params={"apiKey": "097b76f5eee1b5486c8b495410bd84adf5f2"}
                    )
                    ice_servers = response.json()

                    # S·ª≠ d·ª•ng trong webrtc_streamer
                   
                    # S·ª≠ d·ª•ng aiortc
                    
                    webrtc_ctx = webrtc_streamer(
                    key="camera-stream",
                    mode=WebRtcMode.SENDRECV,
                    rtc_configuration={"iceServers": ice_servers},
                    video_processor_factory=ObjectDetectionTransformer,
                    
                   media_stream_constraints = {
                    "video": {
                        "width": {"min": 1280, "ideal": 1920, "max": 3840},
                        "height": {"min": 720, "ideal": 1080, "max": 2160},
                        "frameRate": {"min": 15, "ideal": 30, "max": 60}
                    },
                    "audio": False
},

                    async_processing=False,
                    sendback_audio=False,
                )
                    
                    # Display connection status
                    if st.session_state.peer_connection_id:
                        st.success("‚úÖ Camera ƒëang ho·∫°t ƒë·ªông")
                    else:
                        st.info("üì∑ Nh·∫•n 'B·∫Øt ƒë·∫ßu Camera' ƒë·ªÉ b·∫Øt ƒë·∫ßu camera")
                else:
                    st.error("aiortc kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng s·ª≠ d·ª•ng ch·ª©c nƒÉng upload ·∫£nh.")
                    
            except Exception as e:
                st.error(f"L·ªói k·∫øt n·ªëi camera: {str(e)}")
                st.info("Vui l√≤ng th·ª≠ s·ª≠ d·ª•ng t√πy ch·ªçn 'Upload video/·∫£nh' b√™n d∆∞·ªõi")
                
        else:
            # Alternative: File upload for surveillance
            mtcnn, facenet = load_face_models()
            uploaded_file = st.file_uploader(
                "T·∫£i l√™n video ho·∫∑c ·∫£nh ƒë·ªÉ ph√¢n t√≠ch",
                type=['mp4', 'avi', 'mov', 'jpg', 'jpeg', 'png'],
                key="surveillance_upload"
            )
            
            if uploaded_file is not None:
                if uploaded_file.type.startswith('image'):
                    image = Image.open(uploaded_file)
                    st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_container_width=True)
                    
                    if st.button("Ph√¢n t√≠ch ·∫£nh"):
                        with st.spinner("ƒêang ph√¢n t√≠ch ·∫£nh..."):
                            # Detect khu√¥n m·∫∑t
                            boxes, probs, landmarks, img_array = detect_faces_in_image(image, mtcnn)
                            
                            # V·∫Ω k·∫øt qu·∫£
                            result_image = draw_faces_on_image(image, boxes, probs, landmarks)
                            
                            # Hi·ªÉn th·ªã k·∫øt qu·∫£
                            st.image(result_image, caption="K·∫øt qu·∫£ ph√¢n t√≠ch", use_container_width=True)
                            
                            # Hi·ªÉn th·ªã th√¥ng tin
                            if boxes is not None:
                                st.success(f"Detected {len(boxes)} face")
                                
                                # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt cho m·ªói khu√¥n m·∫∑t
                                for i, (box, prob) in enumerate(zip(boxes, probs)):
                                    with st.expander(f"Face #{i+1} (Relibity: {prob:.2f})"):
                                        # C·∫Øt khu√¥n m·∫∑t t·ª´ ·∫£nh g·ªëc
                                        x1, y1, x2, y2 = [int(p) for p in box]
                                        face_img = Image.fromarray(img_array[y1:y2, x1:x2])
                                        
                                        # Hi·ªÉn th·ªã khu√¥n m·∫∑t ƒë√£ c·∫Øt
                                        st.image(face_img, caption=f"face #{i+1}", width=150)
                                        
                                        # Hi·ªÉn th·ªã th√¥ng tin v·ªã tr√≠
                                        st.text(f"V·ªã tr√≠: X1={x1}, Y1={y1}, X2={x2}, Y2={y2}")
                            else:
                                st.warning("Kh√¥ng Detect khu√¥n m·∫∑t n√†o trong ·∫£nh")
                
                else:  # Video file
                    st.video(uploaded_file)
                    
                    if st.button("Ph√¢n t√≠ch video"):
                        # L∆∞u video t·∫°m th·ªùi ƒë·ªÉ x·ª≠ l√Ω
                        temp_dir = tempfile.mkdtemp()
                        temp_path = os.path.join(temp_dir, "input_video.mp4")
                        output_path = os.path.join(temp_dir, "output_video.mp4")
                        
                        with open(temp_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        
                        with st.spinner("ƒêang ph√¢n t√≠ch video... Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t"):
                            # X·ª≠ l√Ω video
                            results = process_video(temp_path, mtcnn, output_path)
                            
                            # Hi·ªÉn th·ªã video ƒë√£ x·ª≠ l√Ω
                            st.success("Ph√¢n t√≠ch ho√†n t·∫•t!")
                            
                            # Hi·ªÉn th·ªã th·ªëng k√™ t·ªïng quan
                            st.subheader("üìä Th·ªëng k√™ t·ªïng quan")
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("T·ªïng s·ªë frame", results["total_frames"])
                            with col2:
                                st.metric("S·ªë khu√¥n m·∫∑t t·ªëi ƒëa", int(results["max_faces"]))
                            with col3:
                                st.metric("S·ªë khu√¥n m·∫∑t trung b√¨nh", f"{results['avg_faces']:.2f}")
                            with col4:
                                st.metric("S·ªë ng∆∞·ªùi ƒë√£ nh·∫≠n di·ªán", results.get("known_faces", 0))
                            
                            # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt v·ªÅ khu√¥n m·∫∑t ƒë√£ t√¨m ƒë∆∞·ª£c
                            if results.get("known_faces", 0) > 0:
                                st.subheader("üë• Danh s√°ch ng∆∞·ªùi ƒë√£ nh·∫≠n di·ªán")
                                
                                # T·∫°o tabs cho t·ª´ng ng∆∞·ªùi
                                if len(results.get("known_face_names", [])) > 0:
                                    tabs = st.tabs([f"üë§ {name}" for name in results["known_face_names"]])
                                    
                                    for i, (tab, name) in enumerate(zip(tabs, results["known_face_names"])):
                                        with tab:
                                            col_info, col_image = st.columns([2, 1])
                                            
                                            with col_info:
                                                st.write(f"**T√™n:** {name}")
                                                st.write(f"**ID:** {random.randint(100000000000,999999999999)}")
                                                st.write(f"**Tr·∫°ng th√°i:** ƒê√£ nh·∫≠n di·ªán")
                                                
                                                # Hi·ªÉn th·ªã th√¥ng tin embedding (t√πy ch·ªçn)
                                                if "known_face_embeddings" in results and i < len(results["known_face_embeddings"]):
                                                    embedding = results["known_face_embeddings"][i]
                                                    st.write(f"**K√≠ch th∆∞·ªõc embedding:** {embedding.shape if hasattr(embedding, 'shape') else 'N/A'}")
                                            
                                            with col_image:
                                                # Placeholder cho ·∫£nh khu√¥n m·∫∑t (s·∫Ω c·∫ßn th√™m logic ƒë·ªÉ l∆∞u ·∫£nh khu√¥n m·∫∑t)
                                                st.info("·∫¢nh khu√¥n m·∫∑t s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã ·ªü ƒë√¢y")
                                                st.image(results["known_face_images"][i], caption=f"Khu√¥n m·∫∑t c·ªßa {name}", width=150)
                                
                                # Hi·ªÉn th·ªã b·∫£ng t√≥m t·∫Øt
                                st.subheader("üìã B·∫£ng t√≥m t·∫Øt")
                                face_data = []
                                for i, name in enumerate(results.get("known_face_names", [])):
                                    face_data.append({
                                        "STT": i + 1,
                                        "T√™n": name,
                                        "Tr·∫°ng th√°i": "ƒê√£ nh·∫≠n di·ªán",
                                        "L·∫ßn xu·∫•t hi·ªán": "Nhi·ªÅu l·∫ßn"  # C√≥ th·ªÉ t√≠nh to√°n ch√≠nh x√°c h∆°n
                                    })
                                
                                if face_data:
                                    import pandas as pd
                                    df = pd.DataFrame(face_data)
                                    st.dataframe(df, use_container_width=True)
                            
                            else:
                                st.info("Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t n√†o trong video.")
                            
                            # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng khu√¥n m·∫∑t theo frame
                            if results.get("face_count_per_frame"):
                                st.subheader("üìà Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng khu√¥n m·∫∑t theo th·ªùi gian")
                                
                                
                                
                                fig, ax = plt.subplots(figsize=(12, 4))
                                frames = range(len(results["face_count_per_frame"]))
                                ax.plot(frames, results["face_count_per_frame"], linewidth=1, alpha=0.7)
                                ax.fill_between(frames, results["face_count_per_frame"], alpha=0.3)
                                ax.set_xlabel("Frame")
                                ax.set_ylabel("S·ªë l∆∞·ª£ng khu√¥n m·∫∑t")
                                ax.set_title("S·ªë l∆∞·ª£ng khu√¥n m·∫∑t ph√°t hi·ªán theo t·ª´ng frame")
                                ax.grid(True, alpha=0.3)
                                
                                st.pyplot(fig)
                            
                            # Hi·ªÉn th·ªã video ƒë√£ x·ª≠ l√Ω
                            st.subheader("üé• Video ƒë√£ x·ª≠ l√Ω")
                            if os.path.exists(output_path):
                                # N√∫t t·∫£i xu·ªëng
                                with open(output_path, "rb") as file:
                                    st.download_button(
                                        label="üì• T·∫£i xu·ªëng video ƒë√£ x·ª≠ l√Ω",
                                        data=file,
                                        file_name="face_detection_result.mp4",
                                        mime="video/mp4",
                                        use_container_width=True
                                    )
                                
                                # Hi·ªÉn th·ªã video
                                st.video(output_path)
                            
                            # Th√™m th√¥ng tin chi ti·∫øt (c√≥ th·ªÉ thu g·ªçn)
                            with st.expander("üîç Th√¥ng tin chi ti·∫øt"):
                                st.json({
                                    "T·ªïng s·ªë frame": results["total_frames"],
                                    "S·ªë khu√¥n m·∫∑t t·ªëi ƒëa trong 1 frame": int(results["max_faces"]),
                                    "S·ªë khu√¥n m·∫∑t trung b√¨nh": round(results["avg_faces"], 2),
                                    "S·ªë ng∆∞·ªùi ƒë√£ nh·∫≠n di·ªán": results.get("known_faces", 0),
                                    "Danh s√°ch t√™n": results.get("known_face_names", [])
                                })
                            
                            # D·ªçn d·∫πp file t·∫°m
                            try:
                                import shutil
                                shutil.rmtree(temp_dir)
                            except:
                                pass

    with col2:
        st.markdown("""
        <div class="info-card">
        <h3>ƒêi·ªÅu khi·ªÉn Camera</h3>
        <p>C√†i ƒë·∫∑t v√† ƒëi·ªÅu khi·ªÉn camera gi√°m s√°t</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Camera controls
        detection_options = st.multiselect(
            "Ch·ªçn c√°c ƒë·ªëi t∆∞·ª£ng c·∫ßn Detect:",
            ["Khu√¥n m·∫∑t"],
            default=["Khu√¥n m·∫∑t"],
            key="detection_options"
        )
        
        sensitivity = st.slider("ƒê·ªô nh·∫°y Detect", 0, 100, 50, key="sensitivity")
        
        if st.button("Ch·ª•p ·∫£nh", key="capture_btn"):
            st.success("·∫¢nh ƒë√£ ƒë∆∞·ª£c ch·ª•p th√†nh c√¥ng!")
            
        # Add troubleshooting section
        with st.expander("üîß Kh·∫Øc ph·ª•c s·ª± c·ªë"):
            st.markdown("""
            **N·∫øu camera kh√¥ng ho·∫°t ƒë·ªông:**
            1. L√†m m·ªõi trang (F5)
            2. Ki·ªÉm tra quy·ªÅn truy c·∫≠p camera
            3. Th·ª≠ s·ª≠ d·ª•ng tr√¨nh duy·ªát kh√°c
            4. S·ª≠ d·ª•ng t√πy ch·ªçn 'Upload video/·∫£nh'
            """)
JSON_FILE_PATH ="data.json"
def load_data_from_json():
    """
    ƒê·ªçc d·ªØ li·ªáu t·ª´ file JSON
    """
    try:
        if os.path.exists(JSON_FILE_PATH):
            with open(JSON_FILE_PATH, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Chuy·ªÉn ƒë·ªïi t·ª´ JSON sang DataFrame
            if data:  # N·∫øu c√≥ d·ªØ li·ªáu
                df = pd.DataFrame(data)
                return df
            else:
                # T·∫°o DataFrame r·ªóng v·ªõi c√°c c·ªôt c·∫ßn thi·∫øt
                return pd.DataFrame(columns=[
                    'id', 'cccd', 'name', 'dob', 'sex', 
                    'address', 'expdate', 'scan_date', 'image_path'
                ])
        else:
            # T·∫°o DataFrame r·ªóng n·∫øu file kh√¥ng t·ªìn t·∫°i
            return pd.DataFrame(columns=[
                'id', 'cccd', 'name', 'dob', 'sex', 
                'address', 'expdate', 'scan_date', 'image_path'
            ])
    
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file JSON: {str(e)}")
        return pd.DataFrame(columns=[
            'id', 'cccd', 'name', 'dob', 'sex', 
            'address', 'expdate', 'scan_date', 'image_path'
        ])

def save_data_to_json(dataframe):
    """
    L∆∞u DataFrame v√†o file JSON
    """
    try:
        # Chuy·ªÉn ƒë·ªïi DataFrame sang dictionary
        data_dict = dataframe.to_dict('records')
        
        # L∆∞u v√†o file JSON
        with open(JSON_FILE_PATH, 'w', encoding='utf-8') as f:
            json.dump(data_dict, f, ensure_ascii=False, indent=2)
        
        return True, "D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng!"
    
    except Exception as e:
        return False, f"L·ªói khi l∆∞u file JSON: {str(e)}"

def initialize_session_state():
    """
    Kh·ªüi t·∫°o session state v·ªõi d·ªØ li·ªáu t·ª´ JSON
    """
    
    st.session_state.citizens_data = load_data_from_json()

def process_image_for_qr(image):
    """
    X·ª≠ l√Ω ·∫£nh ƒë·ªÉ t√¨m v√† gi·∫£i m√£ QR code
    """
    try:
        # Chuy·ªÉn ƒë·ªïi ·∫£nh sang ƒë·ªãnh d·∫°ng ph√π h·ª£p
        if isinstance(image, np.ndarray):
            frame_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            frame_rgb = np.array(image)

        # Gi·∫£i m√£ QR
        decoded_objects = decode(frame_rgb)
        
        for obj in decoded_objects:
            qr_data = obj.data.decode('utf-8')
            citizen_info = qr_data.split('|')
            
            if len(citizen_info) >= 7:
                # T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh n·∫øu ch∆∞a t·ªìn t·∫°i
                os.makedirs("uploaded_images", exist_ok=True)
                
                # T·∫°o t√™n file ·∫£nh v·ªõi timestamp
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                image_filename = f"citizen_image_{timestamp}.jpg"
                image_path = os.path.join("uploaded_images", image_filename)
                
                # L∆∞u ·∫£nh
                if isinstance(image, np.ndarray):
                    cv2.imwrite(image_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
                else:
                    image.save(image_path)
    
                # T·∫°o b·∫£n ghi m·ªõi
                new_data = {
                    'id': citizen_info[0],
                    'cccd': citizen_info[1],
                    'name': citizen_info[2],
                    'dob': citizen_info[3],
                    'sex': citizen_info[4],
                    'address': citizen_info[5],
                    'expdate': citizen_info[6],
                    'scan_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'image_path': image_path
                }
                
                # C·∫≠p nh·∫≠t DataFrame
                st.session_state.citizens_data = pd.concat([
                    st.session_state.citizens_data,
                    pd.DataFrame([new_data])
                ], ignore_index=True)
                
                # L∆∞u d·ªØ li·ªáu v√†o JSON ngay sau khi th√™m
                success, message = save_data_to_json(st.session_state.citizens_data)
                if not success:
                    st.warning(f"C·∫£nh b√°o: {message}")
                
                return True, "QR code processed successfully!"
                
        return False, "Kh√¥ng t√¨m th·∫•y QR code h·ª£p l·ªá."
    
    except Exception as e:
        return False, f"L·ªói: {str(e)}"

def delete_citizen_record(index):
    """
    X√≥a m·ªôt b·∫£n ghi c√¥ng d√¢n
    """
    try:
        # X√≥a ·∫£nh n·∫øu t·ªìn t·∫°i
        if index < len(st.session_state.citizens_data):
            image_path = st.session_state.citizens_data.iloc[index]['image_path']
            if os.path.exists(image_path):
                os.remove(image_path)
        
        # X√≥a b·∫£n ghi kh·ªèi DataFrame
        st.session_state.citizens_data = st.session_state.citizens_data.drop(index).reset_index(drop=True)
        
        # L∆∞u l·∫°i v√†o JSON
        success, message = save_data_to_json(st.session_state.citizens_data)
        return success, message if success else f"ƒê√£ x√≥a b·∫£n ghi nh∆∞ng c√≥ l·ªói khi l∆∞u: {message}"
        
    except Exception as e:
        return False, f"L·ªói khi x√≥a b·∫£n ghi: {str(e)}"



def get_random_citizen_info():
    """L·∫•y th√¥ng tin c√¥ng d√¢n ng·∫´u nhi√™n"""
    try:
        # Ki·ªÉm tra session state c√≥ d·ªØ li·ªáu kh√¥ng
        if 'citizens_data' not in st.session_state:
            print("Kh√¥ng c√≥ d·ªØ li·ªáu c√¥ng d√¢n trong session state")
            return None
        
        if st.session_state.citizens_data is None or st.session_state.citizens_data.empty:
            print("D·ªØ li·ªáu c√¥ng d√¢n r·ªóng")
            return None
        
        # L·∫•y ng·∫´u nhi√™n m·ªôt citizen
        random_citizen = st.session_state.citizens_data.sample(n=1).iloc[0]
        
        print(f"ƒê√£ ch·ªçn ng·∫´u nhi√™n c√¥ng d√¢n: {random_citizen.get('name', 'Unknown')}")
        return random_citizen
        
    except Exception as e:
        print(f"L·ªói khi l·∫•y citizen ng·∫´u nhi√™n: {e}")
        return None

def clear_all_data():
    """
    X√≥a t·∫•t c·∫£ d·ªØ li·ªáu
    """
    try:
        # X√≥a t·∫•t c·∫£ ·∫£nh
        if len(st.session_state.citizens_data) > 0:
            for _, row in st.session_state.citizens_data.iterrows():
                if os.path.exists(row['image_path']):
                    os.remove(row['image_path'])
        
        # T·∫°o DataFrame r·ªóng
        st.session_state.citizens_data = pd.DataFrame(columns=[
            'id', 'cccd', 'name', 'dob', 'sex', 
            'address', 'expdate', 'scan_date', 'image_path'
        ])
        
        # L∆∞u DataFrame r·ªóng v√†o JSON
        success, message = save_data_to_json(st.session_state.citizens_data)
        return success, "ƒê√£ x√≥a t·∫•t c·∫£ d·ªØ li·ªáu!"
        
    except Exception as e:
        return False, f"L·ªói khi x√≥a d·ªØ li·ªáu: {str(e)}"
# Add this new class for QR code detection
class QRCodeProcessor(VideoProcessorBase):
    def __init__(self):
        self.qr_detected = False
        self.qr_data = None
        self.last_detection_time = 0
        
    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        
        # Convert to RGB for QR detection
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # Detect QR codes
        decoded_objects = decode(img_rgb)
        
        current_time = datetime.now().timestamp()
        
        for obj in decoded_objects:
            # Draw bounding box around QR code
            points = obj.polygon
            if len(points) > 4:
                hull = cv2.convexHull(np.array([point for point in points], dtype=np.float32))
                points = hull
            
            # Draw the bounding box
            n = len(points)
            for j in range(0, n):
                cv2.line(img, tuple(points[j]), tuple(points[(j+1) % n]), (0, 255, 0), 3)
            
            # Add text overlay
            cv2.putText(img, "QR Code Detected", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            # Store QR data (with rate limiting to avoid spam)
            if current_time - self.last_detection_time > 2:  # 2 second cooldown
                self.qr_data = obj.data.decode('utf-8')
                self.qr_detected = True
                self.last_detection_time = current_time
        
        return av.VideoFrame.from_ndarray(img, format="bgr24")

# Update the scan_qr_code function
def scan_qr_code():
    """Enhanced QR code scanning with WebRTC support"""
    st.markdown("<h2 style='text-align: center;'>Qu√©t m√£ QR CCCD</h2>", unsafe_allow_html=True)
    
    # Create tabs for different input methods
    tab1, tab2,tab3 = st.tabs(["üìÅ Upload ·∫¢nh", "üì∑ Camera WebRTC"," Gi·ªõi thi·ªáu c√¥ng ngh·ªá"])
    
    with tab1:
        st.markdown("""
        <div class="info-card">
        <h3>T·∫£i l√™n ·∫£nh QR Code</h3>
        <p>ƒê·ªãnh d·∫°ng h·ªó tr·ª£: JPG, JPEG, PNG</p>
        </div>
        """, unsafe_allow_html=True)
        
        uploaded_file = st.file_uploader(
            "Ch·ªçn ·∫£nh ch·ª©a QR code", 
            type=['jpg', 'jpeg', 'png'],
            key="qr_upload"
        )
        
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_container_width=True)
            
            if st.button("X·ª≠ l√Ω QR Code", key="process_qr"):
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    success, message = process_image_for_qr(image)
                    if success:
                        st.success(message)
                    else:
                        st.error(message)
    with tab2:
        st.markdown("""
        <div class="info-card">
        <h3>Qu√©t QR Code qua Camera</h3>
        <p>S·ª≠ d·ª•ng WebRTC ƒë·ªÉ qu√©t QR code tr·ª±c ti·∫øp t·ª´ camera</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Initialize QR processor in session state
        if 'qr_processor' not in st.session_state:
            st.session_state.qr_processor = QRCodeProcessor()
        
        # WebRTC configuration for QR scanning
        try:
            if AIORTC_AVAILABLE:
                # Get ICE servers
                response = requests.get(
                    "https://iewcom1.metered.live/api/v1/turn/credentials",
                    params={"apiKey": "097b76f5eee1b5486c8b495410bd84adf5f2"}
                )
                ice_servers = response.json()
                
                # Create WebRTC streamer for QR scanning
                webrtc_ctx = webrtc_streamer(
                    key="qr-scanner",
                    mode=WebRtcMode.SENDRECV,
                    rtc_configuration={"iceServers": ice_servers},
                    video_processor_factory=QRCodeProcessor,
                    media_stream_constraints = {
                        "video": {
                            "width": {"min": 1280, "ideal": 1920, "max": 3840},
                            "height": {"min": 720, "ideal": 1080, "max": 2160},
                            "frameRate": {"min": 15, "ideal": 30, "max": 60}
                        },
                        "audio": False
                    },

                    async_processing=False,
                    sendback_audio=False,
                )
                
                # Display instructions
                st.markdown("""
                <div style="background-color: #e3f2fd; padding: 15px; border-radius: 5px; margin: 10px 0;">
                <h4>üìã H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:</h4>
                <ul>
                    <li>Nh·∫•n "START" ƒë·ªÉ b·∫Øt ƒë·∫ßu camera</li>
                    <li>ƒê∆∞a QR code v√†o khung h√¨nh</li>
                    <li>H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông Detect v√† x·ª≠ l√Ω QR code</li>
                    <li>QR code ƒë∆∞·ª£c Detect s·∫Ω c√≥ khung m√†u xanh</li>
                </ul>
                </div>
                """, unsafe_allow_html=True)
                
                # Check for QR detection
                if webrtc_ctx.video_processor:
                    processor = webrtc_ctx.video_processor
                    
                    # Display connection status
                    if webrtc_ctx.state.playing:
                        st.success("‚úÖ Camera ƒëang ho·∫°t ƒë·ªông - S·∫µn s√†ng qu√©t QR code")
                        
                        # Check if QR code was detected
                        if hasattr(processor, 'qr_detected') and processor.qr_detected:
                            st.balloons()
                            st.success("üéâ QR Code ƒë√£ ƒë∆∞·ª£c Detect!")
                            
                            # Process the detected QR code
                            if hasattr(processor, 'qr_data') and processor.qr_data:
                                success, message = process_qr_detection(processor.qr_data)
                                if success:
                                    st.success(f"‚úÖ {message}")
                                    # Display the processed citizen info
                                    display_latest_citizen_info()
                                else:
                                    st.error(f"‚ùå {message}")
                                
                                # Reset detection flag
                                processor.qr_detected = False
                                processor.qr_data = None
                    else:
                        st.info("üì∑ Nh·∫•n 'START' ƒë·ªÉ b·∫Øt ƒë·∫ßu qu√©t QR code")
                
            else:
                st.error("‚ùå WebRTC kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng s·ª≠ d·ª•ng tab 'Upload ·∫¢nh'")
                
        except Exception as e:
            st.error(f"‚ùå L·ªói kh·ªüi t·∫°o camera: {str(e)}")
            st.info("üí° Th·ª≠ l√†m m·ªõi trang ho·∫∑c s·ª≠ d·ª•ng tab 'Upload ·∫¢nh'")
            
            # Fallback to simple camera input
            st.markdown("---")
            st.markdown("### üì∑ Camera ƒë∆°n gi·∫£n (Fallback)")
            camera_image = st.camera_input("Ch·ª•p ·∫£nh QR Code", key="qr_camera_fallback")
            
            if camera_image is not None:
                image = Image.open(camera_image)
                st.image(image, caption="·∫¢nh ƒë√£ ch·ª•p", use_container_width=True)
                
                if st.button("X·ª≠ l√Ω QR Code", key="process_camera_qr_fallback"):
                    with st.spinner("ƒêang x·ª≠ l√Ω..."):
                        success, message = process_image_for_qr(image)
                        if success:
                            st.success(message)
                        else:
                            st.error("Kh√¥ng t√¨m th·∫•y m√£ QR trong ·∫£nh. Vui l√≤ng th·ª≠ l·∫°i.")
    with tab3:
        st.markdown("""
        ### MTCNN (Multi-task Cascaded Convolutional Networks)
        
        MTCNN l√† m·ªôt thu·∫≠t to√°n Detect khu√¥n m·∫∑t hi·ªáu qu·∫£ cao, ho·∫°t ƒë·ªông th√¥ng qua 3 giai ƒëo·∫°n cascade:
        
        1. **P-Net (Proposal Network)**: T·∫°o c√°c h·ªôp ƒë·ªÅ xu·∫•t ban ƒë·∫ßu
        2. **R-Net (Refinement Network)**: Tinh ch·ªânh c√°c h·ªôp ƒë·ªÅ xu·∫•t
        3. **O-Net (Output Network)**: T·∫°o k·∫øt qu·∫£ cu·ªëi c√πng v·ªõi c√°c ƒëi·ªÉm ƒë·∫∑c tr∆∞ng (landmarks)
        
        MTCNN kh√¥ng ch·ªâ Detect khu√¥n m·∫∑t m√† c√≤n x√°c ƒë·ªãnh 5 ƒëi·ªÉm ƒë·∫∑c tr∆∞ng quan tr·ªçng: 2 m·∫Øt, m≈©i v√† 2 g√≥c mi·ªáng.
        
        ### FaceNet
        
        FaceNet l√† m·ªôt m√¥ h√¨nh h·ªçc s√¢u ƒë∆∞·ª£c Google ph√°t tri·ªÉn, chuy·ªÉn ƒë·ªïi khu√¥n m·∫∑t th√†nh vector ƒë·∫∑c tr∆∞ng 128 chi·ªÅu.
        M√¥ h√¨nh n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ:
        
        - Nh·∫≠n d·∫°ng khu√¥n m·∫∑t
        - X√°c minh khu√¥n m·∫∑t (ki·ªÉm tra xem hai khu√¥n m·∫∑t c√≥ ph·∫£i l√† c√πng m·ªôt ng∆∞·ªùi)
        - Ph√¢n c·ª•m khu√¥n m·∫∑t
        
        Trong ·ª©ng d·ª•ng n√†y, ch√∫ng t√¥i s·ª≠ d·ª•ng MTCNN ƒë·ªÉ Detect khu√¥n m·∫∑t v√† c√≥ th·ªÉ m·ªü r·ªông v·ªõi FaceNet ƒë·ªÉ nh·∫≠n d·∫°ng.
        """,unsafe_allow_html=True)
def display_latest_citizen_info():
    """Display information of the most recently added citizen"""
    if not st.session_state.citizens_data.empty:
        latest_citizen = st.session_state.citizens_data.iloc[-1]
        
        st.markdown("""
        <div style="background-color: #e8f5e9; padding: 20px; border-radius: 10px; margin-top: 20px;">
        <h4 style="color: #2e7d32;">üìã Th√¥ng tin c√¥ng d√¢n v·ª´a qu√©t:</h4>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**ID:** {latest_citizen['id']}")
            st.write(f"**S·ªë CCCD:** {latest_citizen['cccd']}")
            st.write(f"**H·ªç v√† t√™n:** {latest_citizen['name']}")
            st.write(f"**Ng√†y sinh:** {latest_citizen['dob']}")
        
        with col2:
            st.write(f"**Gi·ªõi t√≠nh:** {latest_citizen['sex']}")
            st.write(f"**ƒê·ªãa ch·ªâ:** {latest_citizen['address']}")
            st.write(f"**Ng√†y h·∫øt h·∫°n:** {latest_citizen['expdate']}")
            st.write(f"**Th·ªùi gian qu√©t:** {latest_citizen['scan_date']}")

def process_qr_detection(qr_data):
    """Process detected QR code data"""
    try:
        citizen_info = qr_data.split('|')
        
        if len(citizen_info) >= 7:
            st.success("‚úÖ QR code ƒë√£ ƒë∆∞·ª£c Detect v√† x·ª≠ l√Ω th√†nh c√¥ng!")
            
            # Save information to DataFrame
            new_data = {
                'id': citizen_info[0],
                'cccd': citizen_info[1],
                'name': citizen_info[2],
                'dob': citizen_info[3],
                'sex': citizen_info[4],
                'address': citizen_info[5],
                'expdate': citizen_info[6],
                'scan_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'image_path': "camera_capture"
            }
            
            st.session_state.citizens_data = pd.concat([
                st.session_state.citizens_data,
                pd.DataFrame([new_data])
            ], ignore_index=True)
            
            # Display citizen information
            display_citizen_info(citizen_info)
            
    except Exception as e:
        st.error(f"L·ªói x·ª≠ l√Ω QR code: {str(e)}")

def display_citizen_info(citizen_info):
    """Display citizen information in a formatted way"""
    st.markdown("""
    <div style="background-color: #e8f5e9; padding: 20px; border-radius: 10px; margin-top: 20px;">
    <h4 style="color: #2e7d32;">Th√¥ng tin c√¥ng d√¢n:</h4>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    with col1:
        st.write(f"**ID:** {citizen_info[0]}")
        st.write(f"**S·ªë CCCD:** {citizen_info[1]}")
        st.write(f"**H·ªç v√† t√™n:** {citizen_info[2]}")
        st.write(f"**Ng√†y sinh:** {citizen_info[3]}")
    
    with col2:
        st.write(f"**Gi·ªõi t√≠nh:** {citizen_info[4]}")
        st.write(f"**ƒê·ªãa ch·ªâ:** {citizen_info[5]}")
        st.write(f"**Ng√†y h·∫øt h·∫°n:** {citizen_info[6]}")

# Add this to the top of your main() function
def reset_session_on_error():
    """Reset session state if there are WebRTC errors"""
    if 'aiortc_error_count' not in st.session_state:
        st.session_state.aiortc_error_count = 0
    
    if st.session_state.aiortc_error_count > 3:
        st.warning("Detect nhi·ªÅu l·ªói aiortc. ƒêang reset session...")
        for key in list(st.session_state.keys()):
            if 'aiortc' in key.lower() or 'peer' in key.lower():
                del st.session_state[key]
        st.session_state.aiortc_error_count = 0
        st.rerun()

def show_citizen_data():
    st.markdown("<h2 style='text-align: center;'>D·ªØ li·ªáu C√¥ng d√¢n</h2>", unsafe_allow_html=True)
    
    if not st.session_state.citizens_data.empty:
        # Header v·ªõi th·ªëng k√™ v√† n√∫t x√≥a h·∫øt
        col_header1, col_header2, col_header3 = st.columns([2, 1, 1])
        
        with col_header1:
            st.info(f"üìä T·ªïng s·ªë c√¥ng d√¢n: **{len(st.session_state.citizens_data)}**")
        
        with col_header2:
            # N√∫t backup tr∆∞·ªõc khi x√≥a
            if st.button("üíæ Backup d·ªØ li·ªáu", type="secondary"):
                success, message = export_data_to_json()
                if success:
                    st.success(message)
                else:
                    st.error(message)
        
        with col_header3:
            # N√∫t x√≥a t·∫•t c·∫£ v·ªõi confirmation
            if st.button("üóëÔ∏è X√≥a t·∫•t c·∫£", type="secondary"):
                st.session_state.show_delete_all_confirm = True
        
        # Confirmation dialog cho x√≥a t·∫•t c·∫£
        if getattr(st.session_state, 'show_delete_all_confirm', False):
            st.warning("‚ö†Ô∏è **C·∫£nh b√°o:** B·∫°n c√≥ ch·∫Øc ch·∫Øn mu·ªën x√≥a t·∫•t c·∫£ d·ªØ li·ªáu?")
            col_confirm1, col_confirm2, col_confirm3 = st.columns([1, 1, 2])
            
            with col_confirm1:
                if st.button("‚úÖ X√°c nh·∫≠n x√≥a", type="primary"):
                    success, message = clear_all_data()
                    if success:
                        st.success(message)
                        st.session_state.show_delete_all_confirm = False
                        st.rerun()
                    else:
                        st.error(message)
            
            with col_confirm2:
                if st.button("‚ùå H·ªßy b·ªè"):
                    st.session_state.show_delete_all_confirm = False
                    st.rerun()
        
        st.divider()
        
        # Hi·ªÉn th·ªã t·ª´ng b·∫£n ghi v·ªõi n√∫t x√≥a
        for index, row in st.session_state.citizens_data.iterrows():
            with st.expander(f"C√¥ng d√¢n: {row['name']} - CCCD: {row['cccd']}"):
                # Layout ch√≠nh
                col1, col2, col3 = st.columns([1, 2, 0.5])
                
                with col1:
                    if os.path.exists(row['image_path']):
                        st.image(row['image_path'], caption="·∫¢nh CCCD", use_container_width=True)
                    else:
                        st.warning("·∫¢nh CCCD kh√¥ng t·ªìn t·∫°i!")
                
                with col2:
                    st.markdown(f"""
                    **ID:** {row['id']}  
                    **S·ªë CCCD:** {row['cccd']}  
                    **T√™n:** {row['name']}  
                    **Ng√†y sinh:** {row['dob']}  
                    **Gi·ªõi t√≠nh:** {row['sex']}  
                    **ƒê·ªãa ch·ªâ:** {row['address']}  
                    **Ng√†y h·∫øt h·∫°n:** {row['expdate']}  
                    **Ng√†y qu√©t:** {row['scan_date']}
                    """)
                
                with col3:
                    st.markdown("**Thao t√°c:**")
                    
                    # N√∫t x√≥a t·ª´ng b·∫£n ghi
                    if st.button(f"üóëÔ∏è X√≥a", key=f"delete_single_{index}", type="secondary"):
                        st.session_state[f'show_delete_confirm_{index}'] = True
                    
                    # Confirmation cho x√≥a t·ª´ng b·∫£n ghi
                    if getattr(st.session_state, f'show_delete_confirm_{index}', False):
                        st.warning("‚ö†Ô∏è X√°c nh·∫≠n x√≥a?")
                        
                        col_del1, col_del2 = st.columns(2)
                        with col_del1:
                            if st.button("‚úÖ", key=f"confirm_delete_{index}", type="primary"):
                                success, message = delete_citizen_record(index)
                                if success:
                                    st.success(message)
                                    # Reset confirmation state
                                    st.session_state[f'show_delete_confirm_{index}'] = False
                                    st.rerun()
                                else:
                                    st.error(message)
                        
                        with col_del2:
                            if st.button("‚ùå", key=f"cancel_delete_{index}"):
                                st.session_state[f'show_delete_confirm_{index}'] = False
                                st.rerun()
                
                # Th√™m th√¥ng tin b·ªï sung (t√πy ch·ªçn)
                with st.container():
                    st.markdown("---")
                    col_extra1, col_extra2, col_extra3 = st.columns(3)
                    
                    with col_extra1:
                        st.caption(f"üïí Th·ªùi gian qu√©t: {row['scan_date']}")
                    
                    with col_extra2:
                        # T√≠nh tu·ªïi t·ª´ ng√†y sinh
                        try:
                            dob = datetime.strptime(row['dob'], "%d/%m/%Y")
                            age = datetime.now().year - dob.year
                            st.caption(f"üéÇ Tu·ªïi: {age}")
                        except:
                            st.caption("üéÇ Tu·ªïi: N/A")
                    
                    with col_extra3:
                        # Ki·ªÉm tra h·∫°n CCCD
                        try:
                            exp_date = datetime.strptime(row['expdate'], "%d/%m/%Y")
                            days_left = (exp_date - datetime.now()).days
                            if days_left < 0:
                                st.caption("‚ö†Ô∏è **ƒê√£ h·∫øt h·∫°n**")
                            elif days_left < 30:
                                st.caption(f"‚ö†Ô∏è C√≤n {days_left} ng√†y")
                            else:
                                st.caption(f"‚úÖ C√≤n {days_left} ng√†y")
                        except:
                            st.caption("üìÖ H·∫°n: N/A")
                
    else:
        # Th√¥ng b√°o khi kh√¥ng c√≥ d·ªØ li·ªáu
        st.markdown("""
        <div style='text-align: center; padding: 50px;'>
            <h3>üìã Ch∆∞a c√≥ d·ªØ li·ªáu c√¥ng d√¢n n√†o</h3>
            <p>H√£y qu√©t QR code ƒë·ªÉ th√™m th√¥ng tin c√¥ng d√¢n m·ªõi</p>
        </div>
        """, unsafe_allow_html=True)

def export_data_to_json(filename=None):
    """
    Xu·∫•t d·ªØ li·ªáu ra file JSON kh√°c (backup)
    """
    try:
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"citizens_backup_{timestamp}.json"
        
        data_dict = st.session_state.citizens_data.to_dict('records')
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data_dict, f, ensure_ascii=False, indent=2)
        
        return True, f"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c backup v√†o file: {filename}"
    
    except Exception as e:
        return False, f"L·ªói khi backup d·ªØ li·ªáu: {str(e)}"

# Th√™m CSS ƒë·ªÉ l√†m ƒë·∫πp giao di·ªán
def add_custom_css():
    st.markdown("""
    <style>
    /* Style cho n√∫t x√≥a */
    .stButton > button[kind="secondary"] {
        background-color: #ff4b4b;
        color: white;
        border: none;
        border-radius: 5px;
    }
    
    .stButton > button[kind="secondary"]:hover {
        background-color: #ff6b6b;
        color: white;
    }
    
    /* Style cho confirmation buttons */
    .stButton > button[kind="primary"] {
        background-color: #00cc88;
        color: white;
        border: none;
        border-radius: 5px;
    }
    
    /* Style cho expander */
    .streamlit-expanderHeader {
        background-color: #f0f2f6;
        border-radius: 5px;
    }
    
    /* Style cho warning messages */
    .stAlert > div {
        border-radius: 5px;
    }
    </style>
    """, unsafe_allow_html=True)

def show_homepage():
    st.markdown("<h1 style='text-align: center;'>H·ªá th·ªëng Qu·∫£n l√Ω C√¥ng d√¢n</h1>", unsafe_allow_html=True)
    
    # Grid layout cho c√°c ch·ª©c nƒÉng
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="feature-button">
            <h3>Qu√©t QR CCCD</h3>
            <p>Qu√©t m√£ QR t·ª´ CCCD</p>
        </div>
        """, unsafe_allow_html=True)
        
        # N√∫t k·∫øt n·ªëi v·ªõi ch·ª©c nƒÉng qu√©t QR
        if st.button("Qu√©t QR CCCD"):
            st.session_state.page = "scan_qr"
            st.session_state.menu_choice = "Qu√©t QR CCCD"
            st.rerun()
        
    with col2:
        st.markdown("""
        <div class="feature-button">
            <h3>Qu·∫£n l√Ω C√¥ng d√¢n</h3>
            <p>Qu·∫£n l√Ω d·ªØ li·ªáu c√¥ng d√¢n hi·ªáu qu·∫£ v√† d·ªÖ d√†ng.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # N√∫t k·∫øt n·ªëi v·ªõi ch·ª©c nƒÉng qu·∫£n l√Ω d·ªØ li·ªáu
        if st.button("Xem d·ªØ li·ªáu c√¥ng d√¢n"):
            st.session_state.page = "view_data"
            st.session_state.menu_choice = "Xem d·ªØ li·ªáu"
            st.rerun()
        
    with col3:
        st.markdown("""
        <div class="feature-button">
            <h3>Camera Gi√°m S√°t</h3>
            <p>Theo d√µi qua camera an ninh</p>
        </div>
        """, unsafe_allow_html=True)
        
        # N√∫t k·∫øt n·ªëi v·ªõi ch·ª©c nƒÉng camera gi√°m s√°t
        if st.button("Camera gi√°m s√°t"):
            st.session_state.page = "camera"
            st.session_state.menu_choice = "Camera Gi√°m s√°t"
            st.rerun()
    
    # Ki·ªÉm tra n·∫øu c√≥ chuy·ªÉn trang t·ª´ c√°c n√∫t
    if 'page' in st.session_state:
        if st.session_state.page == "scan_qr":
            scan_qr_code()
            st.session_state.page = None
        elif st.session_state.page == "view_data":
            show_citizen_data()
            st.session_state.page = None
        elif st.session_state.page == "camera":
            surveillance_camera()
            st.session_state.page = None

def show_statistics():
    st.markdown("<h2 style='text-align: center;'>Th·ªëng k√™</h2>", unsafe_allow_html=True)
    st.write("Hi·ªÉn th·ªã c√°c s·ªë li·ªáu th·ªëng k√™ li√™n quan ƒë·∫øn c√¥ng d√¢n.")
    # Th√™m code hi·ªÉn th·ªã th·ªëng k√™

def show_settings():
    st.markdown("<h2 style='text-align: center;'>C√†i ƒë·∫∑t</h2>", unsafe_allow_html=True)
    st.write("T√πy ch·ªânh c√°c thi·∫øt l·∫≠p c·ªßa h·ªá th·ªëng t·∫°i ƒë√¢y.")
    # Th√™m code c√†i ƒë·∫∑t
from pathlib import Path

# Cloud environment detection
def is_streamlit_cloud():
    """Detect if running on Streamlit Cloud"""
    return (
        os.getenv("STREAMLIT_SHARING_MODE") == "true" or
        "streamlit.io" in os.getenv("HOSTNAME", "") or
        os.path.exists("/.streamlit")
    )
def setup_cloud_environment():
    """Setup environment cho Streamlit Cloud"""
    
    if is_streamlit_cloud():
        st.sidebar.info("üåê Running on Streamlit Cloud")
        
        # Cloud-specific configurations
        os.environ["OPENCV_VIDEOIO_PRIORITY_MSMF"] = "0"  # Disable MSMF on Windows
        os.environ["OPENCV_VIDEOIO_MSMF_ENABLE_HW_TRANSFORMS"] = "0"
        
        # Temporary directories
        temp_dirs = ["/tmp/uploads", "/tmp/rtc_cache", "/tmp/video_processing"]
        for temp_dir in temp_dirs:
            Path(temp_dir).mkdir(exist_ok=True)
        
        return True
    else:
        st.sidebar.info("üíª Running locally")
        return False
def main():
    # Ki·ªÉm tra ƒëƒÉng nh·∫≠p
    if not st.session_state.logged_in:
        login_page()
        return
    is_cloud = setup_cloud_environment()
    if is_cloud:
        st.info("""
        üåê **Cloud Deployment Notes:**
        - HTTPS enabled automatically
        - Camera access requires user permission
        - File uploads limited to 200MB
        - Temporary files auto-cleaned
        """)
    # Hi·ªÉn th·ªã giao di·ªán ch√≠nh sau khi ƒëƒÉng nh·∫≠p
    st.sidebar.markdown("<h1 style='text-align: center;'>Ch√†o m·ª´ng üì∑</h1>", unsafe_allow_html=True)
    st.sidebar.markdown("<h2 style='text-align: center;'>Qu·∫£n l√Ω C√¥ng d√¢n</h2>", unsafe_allow_html=True)
    
    # Hi·ªÉn th·ªã th√¥ng tin ng∆∞·ªùi d√πng ƒëƒÉng nh·∫≠p
    st.sidebar.markdown(f"""<div style='text-align: center; padding: 10px; background-color: #e8f5e9; 
                        border-radius: 5px; margin-bottom: 20px;'>
                         <b>{st.session_state.username}</b></div>""", 
                        unsafe_allow_html=True)
    
    
    # Kh·ªüi t·∫°o session state
    initialize_session_state()
    menu = [
        "Trang ch·ªß",
        "Qu√©t QR CCCD",
        "Xem d·ªØ li·ªáu",
        "Camera Gi√°m s√°t",
        "Th·ªëng k√™",
        "C√†i ƒë·∫∑t"
    ]
    
    choice = st.sidebar.selectbox(
        "Ch·ªçn ch·ª©c nƒÉng", 
        menu, 
        index=menu.index(st.session_state.menu_choice),
        key="main_menu"
    )
    
    # Hi·ªÉn th·ªã c√°c n√∫t ch·ª©c nƒÉng ph·ª• trong sidebar
    st.sidebar.markdown("---")
    st.sidebar.markdown("### Ch·ª©c nƒÉng nhanh")
    
    if st.sidebar.button("üì∑ Camera"):
        st.session_state.page = "camera"
        st.session_state.menu_choice = "Camera Gi√°m s√°t"
        st.rerun()
      
    if st.sidebar.button("üìä B√°o c√°o"):
        st.session_state.page = "reports"
        st.session_state.menu_choice = "Th·ªëng k√™"
        st.rerun()
        
    if st.sidebar.button("‚öôÔ∏è C√†i ƒë·∫∑t"):
        st.session_state.page = "settings"
        st.session_state.menu_choice = "C√†i ƒë·∫∑t"
        st.rerun()
    
    # N√∫t ƒëƒÉng xu·∫•t
    if st.sidebar.button("üö™ ƒêƒÉng xu·∫•t"):
        st.session_state.logged_in = False
        st.session_state.username = ""
        st.rerun()

    if choice == "Trang ch·ªß":
        show_homepage()
    elif choice == "Qu√©t QR CCCD":
        scan_qr_code()
    elif choice == "Xem d·ªØ li·ªáu":
        show_citizen_data()
    elif choice == "Camera Gi√°m s√°t":
        surveillance_camera()
    elif choice == "Th·ªëng k√™":
        show_statistics()
    elif choice == "C√†i ƒë·∫∑t":
        show_settings()

if __name__ == '__main__':
    main()